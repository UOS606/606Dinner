from fastapi import FastAPI
from pydantic import BaseModel
from transformers import pipeline
import uvicorn

# -----------------------------------------------------------
# 1. FastAPI ì•± ìƒì„± ë° AI ëª¨ë¸ ë¡œë”©
# -----------------------------------------------------------
app = FastAPI()

# í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œ ì €ì¥ì†Œ IDë¥¼ ì§€ì •
try:
    model_path = "KIMKK2K/MrDaebok" 
    classifier = pipeline("text-classification", model=model_path)
    print("âœ… AI ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
except Exception as e:
    print(f"âŒ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    classifier = None


# -----------------------------------------------------------
# 2. ë°ì´í„° í˜•ì‹ ì •ì˜ (Pydantic ëª¨ë¸)
# -----------------------------------------------------------

# Javaì—ì„œ ë³´ë‚¼ ìš”ì²­ ë°ì´í„°ì˜ í˜•ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.
class TextRequest(BaseModel):
    text: str  # ë¬¸ì¥ì€ 'text'ë¼ëŠ” í‚¤ì— ë‹´ê²¨ ì˜¬ ê²ƒìœ¼ë¡œ ì•½ì†í•©ë‹ˆë‹¤.

# Javaë¡œ ëŒë ¤ì¤„ ì‘ë‹µ ë°ì´í„°ì˜ í˜•ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.
class PredictionResponse(BaseModel):
    label: str
    score: float

# -----------------------------------------------------------
# 3. API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
# -----------------------------------------------------------

# "/predict" ì£¼ì†Œë¡œ POST ìš”ì²­ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì°½êµ¬ë¥¼ ì—½ë‹ˆë‹¤.
# response_model=PredictionResponseëŠ” ì‘ë‹µ í˜•ì‹ì„ ê²€ì¦í•˜ê³  ë¬¸ì„œí™”í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
@app.post("/MrDaebak", response_model=PredictionResponse)
def predict_intent(request: TextRequest):
    """
    ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ì˜ë„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë¼ë²¨ê³¼ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not classifier:
        return {"label": "error", "score": 0.0, "message": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    # 1. Javaì—ì„œ ë³´ë‚¸ ë°ì´í„° ì¶”ì¶œ
    input_text = request.text
    print(f"ğŸ“© Javaë¡œë¶€í„° ë¬¸ì¥ ìˆ˜ì‹ : {input_text}")

    # 2. AI ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    # íŒŒì´í”„ë¼ì¸ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    prediction = classifier(input_text)[0]

    # 3. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‘ë‹µ í˜•ì‹ì— ë§ì¶° ë°˜í™˜
    print(f"ğŸ” ì˜ˆì¸¡ ê²°ê³¼: {prediction['label']} (ì‹ ë¢°ë„: {prediction['score']:.2f})")
    return PredictionResponse(label=prediction['label'], score=prediction['score'])

# (ì„ íƒ) ì„œë²„ê°€ ì˜ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê¸°ë³¸ ê²½ë¡œ
@app.get("/")
def read_root():
    return {"status": "AI Inference Server is running"}


# -----------------------------------------------------------
# 4. ì„œë²„ ì‹¤í–‰
# -----------------------------------------------------------
if __name__ == "__main__":
    # uvicorn.run(app, host="0.0.0.0", port=8000)
    # 0.0.0.0ìœ¼ë¡œ í•´ì•¼ ì™¸ë¶€(Java)ì—ì„œ ì ‘ì† ê°€ëŠ¥í•©ë‹ˆë‹¤.
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)